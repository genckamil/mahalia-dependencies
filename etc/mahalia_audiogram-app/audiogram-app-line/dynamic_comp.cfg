# parser "mha.overlapadd":
#
# overlapadd is one of the MHA plugins that perform conversion between
# time domain and spectral domain as a service for algorithms that
# process a series of short time fourier transform signals.  In this
# way, not every MHA plugin that processes spectral signal has to
# perform its own spectral analysis. overlapadd performs both, the
# forward and the backward transform, and can load another MHA plugin
# which analyses and modifies the signal while in the spectral domain.
# The plugin performs the standard process of collecting the input
# signal, windowing, zero-padding, fast fourier transform, inverse
# fast fourier transform, additional windowing, and overlap-add time
# signal output.
#
# The hop size, how much the analysis window is advanced from one
# processing invocation to the next, is not controlled by the
# overlapadd plugin itself, but is determined by the number of audio
# samples per channel and processing block.  In this example
# configuration, the hop size is determined by the "fragsize" setting
# of the MHA itself.  This setting can be found near the top of this
# configuration file.
#
# All other common overlap-add (OLA) and weighted overlap-add (WOLA)
# settings can be configured by setting the configuration variables of
# this overlapadd plugin.
#
# Waveform to spectrum overlap add and FFT method.
# Audio data is collected up to wndlen, than windowed with
# the given window function, zero padded up to fftlength
# (symmetric zero padding or asymmetric zero padding possible),
# and Fast-Fourier-transformed.
# All parameter changes take effect after the next prepare call.

# The overlapadd plugin again loads one plugin that processes the
# signal in the spectral domain.  The plugin loaded here will receive
# the STFT signal and produce a possibly modified version of the STFT
# signal, which is then subjected to inverse FFT transform by the
# overlapadd plugin and finally the overlap-add operation is performed
# to produce the time-domain output signal.
#
# In this configuration, we use again an mhachain plugin to process
# the signal.  Here, mhachain forms a chain of algorithms that pass 
# on spectral STFT signal to each next plugin.  Some plugins in the MHA, 
# like mhachain, can adapt to the domain of the input signal that they receive.  
# Should you happen to configure a plugin to be loaded at a place where it cannot
# process the input signal that it receives, that plugin will raise an
# error, and processing cannot start.
#
# Plugin name
# string
plugin_name = mhachain

# The FFT length, in samples, to use for spectral analysis.  The FFT
# length must be at least as large as the analysis window length,
# which is configured later.  Note that for efficient FFT computation
# the FFT length should be a product of powers of small primes.  The
# openMHA uses MIT's FFTW library version 2 internally, which supports
# efficient analysis also for small primes other than 2, therefore,
# you are not restricted to powers of 2 in the choice of FFT length.
#
# FFT length int:[1,]
fftlen = 512

# parser "mha.overlapadd.wnd":
#
# The window properties are specified in the sub-hierarchy wnd.
#
# Window type.
#
# The data type of the variable wnd.type is keyword_list.  The
# variable offers a choice of predefined symbolic names, one of which
# can be selected.  Most window types offered here should be
# self-explanatory for users with a signal processing background.
# Only the "user" window is a special case where the the window shape
# can be specified sample-by-sample by the user.  For the example
# configuration here we use the hanning window.
# 
# keyword_list:[rect hanning hamming blackman bartlett user]
wnd.type = hanning

# If wnd.type above is user, then the window shape would have to be
# specified here sample-by-sample in the vector wnd.user.  The value
# of each sample would typically between 0 and 1.
# 
# User provided window (used if window type==user).
# vector<float>
wnd.user = []

# The window length, in samples.  The window length should be at least
# as long as the hop size (determined by the fragsize setting outside
# of the overlapadd plugin), and must be at most as long as the FFT
# length.  A typical value would be for the window size to be either
# exactly two (like here) or four times the hop size, to achieve 50%
# or 75% overlap, respectively.  If the signal is not only analyzed in
# the spectral domain, but also modified with frequency-dependent
# gains, it is recommended to choose the window length shorter than
# the FFT length to have some zero padding to pick up the time-domain
# convolution from the corresponding frequency-domain modifications.
#
# window length/samples
# int:[1,]
wnd.len = 256

# If the fft length is greater than the window length, then this
# variable determines the relative placement of the window inside the
# fft analysis buffer.
# 
# window position
# (0 = beginning, 0.5 = symmetric zero padding, 1 = end)
# float:[0,1]
wnd.pos = 0.5

# In common overlap-add processing, the window would be applied as an
# analysis window before transforming to the frequency domain.
# However, there are other use cases (namely WOLA, weighted
# overlap-add), where one commonly restricts the resynthesized time
# signal that is produced by the inverse FFT with a synthesis window
# to the original extent of the analysis window to restrict filter
# "ringing".  You would usually split one of the common analysis
# window used in overlap-add processing, by applying an exponent of
# 0.5 to all the window samples and apply the analysis window before
# the FFT and apply the synthesis window after the inverse FFT.  Note
# that this is not commonly done in hearing aid signal processing, but
# the MHA supports it should you need it.
#
# An exponent of 1 here means that the window is completely applied
# before the FFT is performed.  Values lesser than one mean that all
# window weights are exponentiated by this exponent (named wnd.exp
# here) before the weights are applied to the input signal. Then, the
# exponent (1-wnd.exp) is applied to the window weights before it is
# applied as a synthesis window to the time signal that is produced by
# the inverse FFT.
#
# If you perform standard overlap-add processing (OLA), and not
# weighted overlap-add (WOLA), then leave this at its default value,
# 1.
#
# window exponent to be applied to all elements of window function
# float
wnd.exp = 1

# parser "mha.overlapadd.zerownd":
#
# The settings in the sub-parser "zerownd" define a weighting
# operation performed on the regions of the FFT buffer that are
# pre-filled with the zero-padding.  If the signal is modified in the
# spectral domain, then these regions of the FFT buffer usually
# contain non-zero signal samples after the inverse FFT has been
# performed.  This is caused by the convolution with the impulse
# response that corresponds to the spectral changes that the spectral
# algorithms have performed.
# 
# If the effective impulse response exceeds the length of the
# zero-padding regions in the FFT buffer, then this will cause
# temporal aliasing effects that may be perceptible to the hearing
# impaired user.  To improve the perceptual consequences, one might
# apply a post-window to attenuate the signal energy in the
# zero-padding area.  You can choose the shape of this post-window
# with the configuration setting zerowind.type. This window will be
# split in two and each part applied to the respective zero-padding
# regions at the beginning and at the end of the FFT buffer.  Note
# that a rectangular window will have a weight of one everywhere and
# therefore will not affect these regions and will not improve the
# temporal aliasing artifacts.  The default setting is a rectangular
# window with no effect.
#
# zero padding post window type
# Window type.
# keyword_list:[rect hanning hamming blackman bartlett user]
zerownd.type = rect

# If the window type selected in zerownd.type is "user", then the weigths
# of the desired window have to be specified here.
# 
# User provided window (used if window type==user).
# vector<float>
zerownd.user = []

# parser "mha.overlapadd.mhachain":
#
# This mhachain plugin instance forms a signal processing chain in the
# spectral domain: It's input signal is the STFT signal produced by
# the overlapadd plugin, and its output signal is processed by the
# same overlapadd instance to resynthesize it to a time domain signal.
# 
# MHA Chain
#
# The plugins used to form a signal processing chain are loaded by the
# mhachain plugin when the assignment to the configuration parameter
# algos is executed.  This is a vector of strings, where the vector
# value is delimited by square brackets, and the vector's elements are
# separated by spaces.
# 
# list of plugins
# vector<string>
mhachain.algos = [route fftfilterbank dc combinechannels]

# parser "mha.overlapadd.mhachain.route":
#
# We pass only the frontal channels to the dynamic compressor. For this 
# we use the route plugin.
#
# Output channels routed out
mhachain.route.out = [:0 :1]

# parser "mha.overlapadd.mhachain.fftfilterbank":
# 
# FFT based filterbank with overlapping filters
#
# For the dynamic compression which adapts the signal levels in the
# different frequency bands for better audibility of the hearing
# impaired opemMHA users, the signal has to be split into frequency
# band. We do this here with the help of the MHA plugin fftfilterbank,
# which separates our (here) 2 broadband audio channels and produces
# (here) 2*9 narrowband audio channel, with 9 frequency bands
# produced for each input broadband audio channel.
#
# FFT filterbank is not limited to 2 input channels, the above
# paragraph just uses the current settings used here as an example.

# fftfilterbank groups sets of FFT bins into frequency bands.
#
# Further below we will specify the center frequencies of these frequency
# bands.  Here, we specify in what units we want to give the
# frequencies below.  The default unit to specify frequencies in the
# MHA is Hertz [Hz], but at some places, users have the choice of
# selecting different frequency units.  Here, we choose that we want
# to specify the frequencies in Hertz.
#
# Frequency unit
# keyword_list:[Hz kHz Oct Oct/3 Bark Erb ERB_Glasberg1990]
mhachain.fftfilterbank.unit = Hz

# The configuration setting f of the fftfilterbank plugin expects a
# vector with the center frequencies of the individual frequency
# bands. The unit for the frequencies is Hertz.
#
# Frequencies
# vector<float>
mhachain.fftfilterbank.f = [177 297 500 841 1414 2378 4000 6727 11314]

# The frequency bands that the fftfilterbank plugin produces can have
# different shapes along the frequency axis.  The shapes and also the
# cross-over frequencies between adjacent frequency bands can be
# computed on different frequency scales, e.g. linear or logarithmic
# scales.  Here we choose the logarithmic frequency scale.
#
# frequency scale of filter bank
# keyword_list:[linear bark log erb ERB_Glasberg1990]
mhachain.fftfilterbank.fscale = log

# Frequency bands in the fftfilterbank can have different shapes
# along the frequency axis.  Here we select a rectangular shape, which
# also has the effect that frequency bands will not overlap,
# i.e. every frequency bin is part of only exactly one frequency band.
# 
# filter overlap type
# keyword_list:[rect linear hanning exp gauss]
mhachain.fftfilterbank.ovltype = rect

# Above, when setting the configuration variable f, we used center
# frequencies.  We could also have specified the edge frequencies if
# we did the respective setting here.  When we specify center
# frequencies, then the cross-over frequencies between adjacent
# frequency bands are computed as the mean between the adjacent center
# frequencies on the frequency scale specified by the variable fscale.
# Also, in center frequency mode, the lowest frequency band always
# extends to frequency 0Hz, while the highest frequency band always
# extends to the Nyquist frequency.
#
# keyword_list:[center edge]
mhachain.fftfilterbank.ftype = center

# parser "mha.overlapadd.mhachain.dc":
# 
# dynamic compression
#
# Our standard dynamic compression algorithm measures the input sound
# level in each frequency band and looks up the gain to be applied in
# a gain table, and applies the gain to the signal in each respective
# band.

# Dynamic compression works by amplifying the signal with gains that
# depend on the level of the input signal itself.  Multi-band dynamic
# compression performs input signal level measurement in each
# frequency band to deduce the gain applicable to the respective
# frequency band.  Applicable gains would usually be higher for low
# input levels, and lower for high input levels, to compress the
# dynamimc range of the input signal into a smaller dynamic range at
# the output of the compressor.
#
# Because the applicable gain depends on the frequency band as well as
# on the input level, we use a 2-dimensional matrix to specify
# applicable gains. The gaintable matrix has one row of gains for each
# frequency band from the left audio channel, followed by one row of
# gains for each frequency band from the right audio channel.  The
# gains given are in dB.  Rows are enclosed by square brackets and
# separated by semicola.  The entire matrix is enclosed in an
# additional pair of square brackets.
#
# The first element in each row (i.e., taken together, the first
# column) specifies the gain in dB to be applied if the input level in
# the respective frequency band is equal to the value of the gtmin
# element given for that respective band (see gtmin description
# further below).
#
# The following elements in each row specify the gains in dB to be
# applied for other input values, where the input level difference
# between the individual elements in each row of the matrix is
# determined by the value of gtstep for the respective band (see
# gtstep description further below).
#
# This way, each row specifies the gains to be applied to the
# respective frequency bands for certain discrete input levels.  The
# actual input levels of the signal will regularly be different from
# any of these discrete input levels.  Therefore, the gain values in
# the rows are interpolated as well as extrapolated.
#
# The gain values that we use here in this example are all zero and
# therefore, the sound levels are not amplified or compressed until
# the gain values are altered.  We provide a fitting tool that can be
# used to change the settings in a running openMHA instance to provide
# adequate amplification and compression for individual hearing
# losses.  Please refer to the GUI manual for a description how to use
# this tool (openMHA_gui_manual.pdf).
#
# gaintable data in dB gains
# matrix<float>
mhachain.dc.gtdata = [...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]; ...
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]

# Vector of input sound pressure levels for which the gains in the
# leftmost column of the matrix "gtdata" above should be applied.
# Each input sound level given here belongs to a different frequency
# band. If only one value is given here, then this only value will
# apply to all matrix rows / frequency bands.
#
# input level for first gain entry in dB SPL
# vector<float>
mhachain.dc.gtmin = [0]

# Vector of step sizes in dB between discrete sound pressure levels
# that determine the supporting points in the mapping from input sound
# levels to applicable gains in matrix "gtdata" above.  Each entry in
# this vector specifies the step size for a different row of gtdata.
# If only one value is given here, then this only value will apply to
# all rows / frequency bands.
#
# Each input sound level given here belongs to a different frequency
# band. If only one value is given here, then this only value will
# apply to all frequency bands.
#
# level step size in dB
# vector<float>
mhachain.dc.gtstep = [4]

# The dynamic compressor employs a common attack/decay low-pass filter
# to determine the input level.  This vector describes the attack time
# constants.  Each element corresponds to one frequency band. If only
# one value is given here, then this only value will apply to all
# frequency bands.
#
# attack time constant in s
# vector<float>
mhachain.dc.tau_attack = [0.02]

# The dynamic compressor employs a common attack/decay low-pass filter
# to determine the input level.  This vector describes the decay or
# release time constants.  Each element corresponds to one frequency
# band. If only one value is given here, then this only value will
# apply to all frequency bands.
#
# decay time constant in s
# vector<float>
mhachain.dc.tau_decay = [0.1]

# Name of fftfilterbank plugin.  Used to extract frequency information.
# string
mhachain.dc.fb = fftfilterbank

# The fftfilterbank that splits the broadband channels into frequency
# bands for this compressor outputs the frequency bands as separate
# audio channels. Without additional knowledge, the dynamic compressor
# cannot determine whether an 18 channel input signal that it receives
# has been generated from 2 broadband channels that have been split
# into 9 bands each (like we do in this example), or maybe from 3
# broadband channels that have been split into 6 bands each.  The
# following setting tells the compressor the name of an algorithm
# communication variable where the fftfilterbank has stored
# information about the original number of broadband channels.
#
# name of audio channel number variable (empty: broadband)
# string
mhachain.dc.chname = fftfilterbank_nchannels

# parser "mha.overlapadd.mhachain.combinechannels":
# 
# Channel combiner
#
# The fftfilterbank has split the signal into frequency bands.  To be
# able to combine the frequency bands back into broadband channels,
# the combinechannels plugin needs to know how many broadband channels
# have been split into bands.  The fftfilterbank that splits the
# broadband channels into frequency bands for this compressor outputs
# the frequency bands as separate audio channels. Without additional
# knowledge, the combinechannels plugin cannot determine whether an 18
# channel input signal that it receives has been generated from 2
# broadband channels that have been split into 9 bands each (as it is
# the case in this example), or maybe from 3 broadband channels that
# have been split into 6 bands each.  The following setting tells the
# combinechannels plugin how many broadband output channels it should
# regenerate.
#
# Number of output channels
# int:[1,]
mhachain.combinechannels.outchannels = 2

# Local Variables:
# indent-tabs-mode: nil
# coding: utf-8-unix
# End:
